{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying Bias in AI\n",
        "\n",
        "The activity is a programming exercise based on [identifying bias in AI](https://www.kaggle.com/code/alexisbcook/exercise-identifying-bias-in-ai/notebook), which was released under the Apache 2.0 open source licence. This adapation has been development in the context of the erasmus+ project [FAIAS](https://fosteringai.github.io/). \n",
        "\n",
        "In this exercise we will use labeled data to train a model to decide whether a comment or a text is toxic or not. We will explore how and why our trained model can be biased. All code that is necessary to complete the exercise has been added, but you are free to add more code and experiment. \n",
        "\n",
        "The easiest way to get started with this notebook is to open it in [Google Colab](https://colab.research.google.com/). This way you can run the code without any required setup on your machine. Of course, if you are familiar with Python and Jupyter Notebooks, you can install the necessary dependencies on your computer and run it there. If you are working with Google Colab, extra explanations will be given throughout the notebook. \n",
        "\n",
        "This notebooks contains several so called cells. These are the areas where you can write code. In this notebook all necessary code has already been added for you. To run a piece of code, you can click on \"run cell\" to the left of the code. The order in which you run the cells is important. For instance, in the very first cell, we are importing several packages. These are used in other cells. If you run the other cells first without having run the cells in which you import the packages, you will get an error message. Similarly, it is also important that you first upload the data to Google Colab before you can use it.\n",
        "\n",
        "If you leave the notebook idle for too long (think hours), its runtime is automatically disconnected. In this case you will need to restart and run the cells again. \n"
      ],
      "metadata": {
        "id": "iycXLa8A817e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data and train model"
      ],
      "metadata": {
        "id": "CykhfeB23UYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing all packages and load data\n",
        "\n",
        "Before you can use this notebook you need to upload the data file *toxic_data.csv*. If you are using Google Colab, at the left-hand side of this screen, you go to *files* and then select *upload to session storage*. Note that you might have to wait until you are connected to a runtime before you can click on *upload to session storage*. \n",
        "\n",
        "It will take a while before the file has been uploaded completely. As long as the file is still uploading, you will see a progress ring at bottom of the file screen (with the name of the file next to it). \n",
        "\n",
        "Then, we need to import all packages that are needed to run the code in this notebook. "
      ],
      "metadata": {
        "id": "KsOHrtAI84Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "9oqXdx-W9NZ_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By running the following cell, you make sure to obtain the same results each time you run the code in this notebook. If you do not run this cell, sampling might be done differently and results will be different."
      ],
      "metadata": {
        "id": "VOYxr3rC_GHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "Yf9lRAZ0_v_F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need to load the data you have uploaded earlier. \n",
        "\n",
        "Verify that the name of the uploaded file coincides with the name in the following cell: eg if the file name is *toxic_data.csv*, then in the following cell you must have \n",
        "\n",
        "```data = pd.read_csv(\"toxic_data.csv\", encoding=\"utf8\")```\n",
        "\n",
        "It is important to make sure that the file has been uploaded completely before running the following cell. As long as the file is still uploading, you will see a progress ring at bottom of the file screen (with the name of the file next to it). If you do run the cell while it is still being uploaded, you will get an error message. Rerun the cell when it is ready."
      ],
      "metadata": {
        "id": "Tz9mjtTY_44x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"toxic_data.csv\", encoding=\"utf8\")"
      ],
      "metadata": {
        "id": "GhRZz8UTA0hj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variable `data` now refers to a pandas DataFrame. A DataFrame organizes data into a 2-dimensional table of rows and columns, intuitively, you can think of a DataFrame as a spreadsheet. In the next section we will explore the data a bit further.  "
      ],
      "metadata": {
        "id": "siAb-BhDA4nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data exploration \n",
        "\n",
        "Before continuing, let us take a look at some properties of the data. The shape will tell us how many rows and columns the data contains:"
      ],
      "metadata": {
        "id": "j7MKiON6CVVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (number of rows, number of columns)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iyOdhoRCfRU",
        "outputId": "4a230755-ed86-4483-e014-c32ca7bbd3a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90902, 46)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The names of the columns present in the data can also easily be retrieved. Note that the list is rather large. If you want to hide it click on the cross (*clear output*)."
      ],
      "metadata": {
        "id": "IluHVMboCqhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# column names\n",
        "list(data.columns)"
      ],
      "metadata": {
        "id": "j6OT7__uCwjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise we are going to work with two columns: `'comment_text'` and `'target'`. \n",
        "\n",
        "Let us look at the first rows. We can access the first rows by using the `head` method. You can change the parameter in order to retrieve more rows. "
      ],
      "metadata": {
        "id": "fone-HB-C5hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "ZCFwA3DsJbjp",
        "outputId": "de59f838-ea30-45b8-9b45-5d8d790d30cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0      id    target  \\\n",
              "0           0   59856  0.893617   \n",
              "1           1  239607  0.912500   \n",
              "\n",
              "                                        comment_text  severe_toxicity  \\\n",
              "0               haha you guys are a bunch of losers.         0.021277   \n",
              "1  Yet call out all Muslims for the acts of a few...         0.050000   \n",
              "\n",
              "   obscene  identity_attack   insult  threat  asian  ...  article_id  \\\n",
              "0   0.0000         0.021277  0.87234  0.0000    0.0  ...        2006   \n",
              "1   0.2375         0.612500  0.88750  0.1125    0.0  ...       26670   \n",
              "\n",
              "     rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
              "0  rejected      0    0    0      1         0              0.0   \n",
              "1  approved      0    0    0      1         0              0.0   \n",
              "\n",
              "   identity_annotator_count  toxicity_annotator_count  \n",
              "0                         4                        47  \n",
              "1                         4                        80  \n",
              "\n",
              "[2 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-496b991f-80b7-4a03-aacc-c6437046f867\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>severe_toxicity</th>\n",
              "      <th>obscene</th>\n",
              "      <th>identity_attack</th>\n",
              "      <th>insult</th>\n",
              "      <th>threat</th>\n",
              "      <th>asian</th>\n",
              "      <th>...</th>\n",
              "      <th>article_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>funny</th>\n",
              "      <th>wow</th>\n",
              "      <th>sad</th>\n",
              "      <th>likes</th>\n",
              "      <th>disagree</th>\n",
              "      <th>sexual_explicit</th>\n",
              "      <th>identity_annotator_count</th>\n",
              "      <th>toxicity_annotator_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>59856</td>\n",
              "      <td>0.893617</td>\n",
              "      <td>haha you guys are a bunch of losers.</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.87234</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>239607</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>Yet call out all Muslims for the acts of a few...</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.2375</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.88750</td>\n",
              "      <td>0.1125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26670</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 46 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-496b991f-80b7-4a03-aacc-c6437046f867')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-496b991f-80b7-4a03-aacc-c6437046f867 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-496b991f-80b7-4a03-aacc-c6437046f867');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are only interested in two specific columns, we filter the data, eg `data[\"target\"]` contains the `\"target\"` column. `data[\"target\"]` is not a DataFrame anymore but a Pandas Series which is a one-dimensional array. We can still look at the first rows by using the `head` method."
      ],
      "metadata": {
        "id": "NK8B-uwDL75F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"comment_text\"].head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdRRnMOXDk6d",
        "outputId": "fa50d507-c049-42b3-fcb6-5bc3d23cdbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 haha you guys are a bunch of losers.\n",
              "1    Yet call out all Muslims for the acts of a few...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All rows contain a index, this is like an identifier. In our case, the indices are a sequence of integers starting with 0. This is not always the case, e.g. you could split a DataFrame into two subsets and in one of the resulting DataFrames or Series the first row will not have index 0 anymore, but will have the index it had in the original DataFrame.\n",
        "\n",
        "You look at the row at a specific index by using the `loc` property with takes the index as input."
      ],
      "metadata": {
        "id": "4UifIhdTYT9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comment with index 1\n",
        "data[\"comment_text\"].loc[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "G4hB1_6LMbGY",
        "outputId": "3aee4045-c7b4-4e84-a190-a77bf2ea1f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Yet call out all Muslims for the acts of a few will get you pilloried.   So why is it okay to smear an entire religion over these few idiots?  Or is this because it's okay to bash Christian sects?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# target of comment with index 1\n",
        "data[\"target\"].loc[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MHoTBKnDVGr",
        "outputId": "a6dbdafd-bf06-406e-d40e-4bcfbf89cd05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9125"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is a subset of the data that was used in the Jigsaw Unintended Bias in Toxicity Classification competition. In the orginal dataset `\"target\"` is a number between 0 and 1, where closer to 1 means more toxic and closer to 0 less toxic. In the dataset we are using all rows with target between 0.3 and 0.7 have been filtered out. This means that comments with a target > 0.7 can be considered as toxic and comments with a target < 0.3 as non toxic. \n",
        "\n",
        "To visualize how many comments we have for each range of target values, you can run the following cell:"
      ],
      "metadata": {
        "id": "Hb5zKH76EIcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"target\"].hist(bins=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "sqL06O46F4ZZ",
        "outputId": "3f34cb76-f90b-4a1e-9832-717b449c504f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to know how many rows have target more than 0.7, or less than 0.3, you can run the following two cells. You will see the data set is nicely divided into toxic (>0.7) and non-toxic (<0.3)."
      ],
      "metadata": {
        "id": "oEEF88jNGTgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[data[\"target\"] > 0.7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X2193B4Fs_B",
        "outputId": "dc17d1db-e663-43ea-c6ea-436a7edf30f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45451"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[data[\"target\"] < 0.3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx4evWcqGPyp",
        "outputId": "34660606-6fa7-464f-8480-5a558df47f84"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45451"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing\n",
        "\n",
        "We will transform the data such that it is easier to work with. We want to predict whether a comment is toxic or not, hence it is easier to work with 0/1 instead of a range of numbers between 0 and 1. To achieve this we will map each number < 0.3 to 0 (not toxic) and each number > 0.7 to 1 (toxic). We will save the resulting column in a variable called `target`:"
      ],
      "metadata": {
        "id": "HFEq_pMyG_nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = (data[\"target\"] > 0.7).astype(int)"
      ],
      "metadata": {
        "id": "d-cUj-5pIAuZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The other column we are interested in, is the `\"comment_text`\" column. Let us save that column in a variable called `comment`. As before `comment` now refers to a Pandas Series."
      ],
      "metadata": {
        "id": "xQBGQp3YIDzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comment = data[\"comment_text\"]"
      ],
      "metadata": {
        "id": "p2m_9yzvIQo-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(comment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oblunxFWIKOs",
        "outputId": "fbc3a82f-8200-4f77-84db-89fda720392e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us take a look at the first rows:"
      ],
      "metadata": {
        "id": "DTGjnUUJIVBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comment.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgIFSpkdIa9e",
        "outputId": "9ddfb65b-851f-49d9-899c-b8865bc313cb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 haha you guys are a bunch of losers.\n",
              "1    Yet call out all Muslims for the acts of a few...\n",
              "2    This bitch is nuts. Who would read a book by a...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A6gPLhvIhkP",
        "outputId": "8f8f1230-1461-4a1d-9435-e66a3342283e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we split the data into two subsets: a training set and a test set. In machine learning, you use training data to train a model. You then test it on examples that the model has not seen before, the examples in the test set. We will use the `train_test_split` method that we imported earlier. We add two optional parameters:\n",
        "- `test_size` which we set to 0.3: this means that we split the original data into 70% training data and 30% test data\n",
        "- `stratify` on target which means that the proportion of toxic/non toxic in training and test data will be the same as in the original data set"
      ],
      "metadata": {
        "id": "FFctpMUVXvsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comment_train, comment_test, target_train, target_test = train_test_split(comment, target, test_size=0.3, stratify=target)"
      ],
      "metadata": {
        "id": "zj1aSuj0msyH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have split the data up in training data and test data:\n",
        "- training data consists of two columns `comment_train` and `target_train`\n",
        "- test data consists of two columns `comment_test` and `target_test`\n",
        "\n",
        "The 4 columns are Pandas Series. If you check the first rows of `comment_train` you will see that the index does not start with 0 anymore. This is because the original data was reshuffled and split."
      ],
      "metadata": {
        "id": "vWTtZX2_EPiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comment_train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJC1l4rNIEZS",
        "outputId": "0cbe785f-c250-4c43-d9d6-0c341fb2fcc3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56549    I thought the longliner's were all about local...\n",
              "21515    Do you grow your own foods?  Hoard your own ca...\n",
              "84940    \"...they have also begun arresting people who ...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comment_train.loc[56549]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Tw2BH2XAF1Zg",
        "outputId": "dee6da2d-2d79-4f98-f0ad-73ac34823c3d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I thought the longliner's were all about local labor, local Hawaiian's working the trade for local dollars and local consumption. Isn't that what they said when they got all them folks to stand up in opposition to the expansion of Papahanaumokuakea? I don't know about anyone else, but I feel as if Westpac has been hustling us all along.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_train.loc[56549]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATzWGk9eaaYX",
        "outputId": "ae0ea77f-75d7-42a9-b58b-09afec136fab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stratify parameter makes sure that the training data is evenly split into toxic and not toxic, like the orginal data."
      ],
      "metadata": {
        "id": "c03Dwx2balNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of toxic data in the training data\n",
        "len(target_train[target_train == 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVpzq1jqGA-v",
        "outputId": "650fac27-2a14-4618-92fc-a9f6854ea1e1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31816"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of non-toxic data in the training data\n",
        "len(target_train[target_train == 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEGvldTqGJZu",
        "outputId": "ba0357eb-3b0d-472a-c542-af7e8e3822df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31815"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with words and vocabularies\n",
        "\n",
        "We want to map comments to targets (0 or 1). For that we need to add a bit of structure, we need a way to uniquely represent our comments. We will do this by creating a vocabulary using the training data. Every sentence (not necessarily present in the training data) can then be represented using this vocabulary: every sentence is converted to a vector of length size of the vocabulary.\n",
        "\n",
        "We will use the earlier imported `CountVectorizer` to achieve this. See [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) for more info."
      ],
      "metadata": {
        "id": "4LR2vVR3XoCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Learn a vocabulary from the training data\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(comment_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "qmV5Gk5jhARt",
        "outputId": "9a6a04ac-03e6-4895-caf4-c9cf1aa652f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we have to transform our comment data using this representation. \n",
        "- `X_train`: the comments from the training data\n",
        "- `X_test`: the comments from the test data"
      ],
      "metadata": {
        "id": "WQwuGiM2iSME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = vectorizer.transform(comment_train)\n",
        "X_test = vectorizer.transform(comment_test)"
      ],
      "metadata": {
        "id": "wGD20eMjidvj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model\n",
        "\n",
        "In our example, we will use logistic regression. A logistic model models the probability of an event taking place, here toxic or not toxic. This type of model is often used for classification. \n",
        "\n",
        "We will use the `LogisticRegression` model we imported earlier. More information can be found in [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). \n",
        "\n",
        "We will use the training data (`X_train` and `target_train`) to fit the model and then we will test its accuracy on the test data (`X_test` and `target_test`).\n"
      ],
      "metadata": {
        "id": "G2SZF-B8i5Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit training data\n",
        "classifier = LogisticRegression(max_iter= 2000)\n",
        "classifier.fit(X_train, target_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "MJpiFTnqzvu0",
        "outputId": "5e5e1bf1-d23c-4d02-dc5c-3671bb9ef0a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=2000)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.score(X_test, target_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44OTmt-H0Qp8",
        "outputId": "62b6baed-6340-4804-c8b4-bf41c2c8ffc1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9297422170070772"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy on the test data is very high! Almost 93% of the test examples were classified correctly.\n",
        "\n",
        "Let's write a function we can reuse. This function takes one parameter (a comment) and uses the classifier to predict whether the comment is toxic and prints out whether that comment is toxic or not."
      ],
      "metadata": {
        "id": "wB5Js4Bx0XI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_comment(comment):\n",
        "  prediction = classifier.predict(vectorizer.transform([comment]))[0]\n",
        "  if prediction == 0:\n",
        "    print(\"NOT TOXIC\", comment)\n",
        "  else:\n",
        "    print(\"TOXIC\", comment)"
      ],
      "metadata": {
        "id": "w3ZWUgFF1EKl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the previous cell, you can now use the function `classify_comment` on any sentence you like. Just make sure they are between quotes, e.g. \"I love cats.\" Python needs these quotes to know they are sentences (strings)."
      ],
      "metadata": {
        "id": "Q2zUdp9_1SRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classify_comment(\"I love cats.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pywkjvTN1Rxd",
        "outputId": "f063f7fb-ad04-4a1b-f13f-a77761d411d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT TOXIC I love cats.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classify_comment(\"I hate cats.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKOCIe841my3",
        "outputId": "cf977a53-9da7-4c2b-b01a-9fd8d34e9c9d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT TOXIC I hate cats.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How does the model make decisions?\n",
        "\n",
        "What happens behind the scenes is that the model assigns to each word in the vocabulary a coefficient, where a higher coefficient denotes more toxic. In the next cell, let us print the 10 most toxic words in the vocabulary, together with their coefficient."
      ],
      "metadata": {
        "id": "MLvYNstS1stu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get 10 most toxic words\n",
        "coefficients = pd.DataFrame({\"word\":list(sorted(vectorizer.vocabulary_.keys())), \"coeff\": classifier.coef_[0]})\n",
        "coefficients.sort_values(by=['coeff']).tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SDPO85i82tgQ",
        "outputId": "38405540-91ed-4ba7-cab2-18f30fd2e080"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            word     coeff\n",
              "25824  hypocrite  6.176646\n",
              "34386      moron  6.288207\n",
              "38522   pathetic  6.507094\n",
              "16943       dumb  6.590523\n",
              "12943       crap  6.602809\n",
              "25985    idiotic  6.968227\n",
              "50099  stupidity  7.565816\n",
              "25993     idiots  8.628643\n",
              "25982      idiot  8.634393\n",
              "50086     stupid  9.609074"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a14573e9-dd23-4d25-a89c-e78b73a81631\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25824</th>\n",
              "      <td>hypocrite</td>\n",
              "      <td>6.176646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34386</th>\n",
              "      <td>moron</td>\n",
              "      <td>6.288207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38522</th>\n",
              "      <td>pathetic</td>\n",
              "      <td>6.507094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16943</th>\n",
              "      <td>dumb</td>\n",
              "      <td>6.590523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12943</th>\n",
              "      <td>crap</td>\n",
              "      <td>6.602809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25985</th>\n",
              "      <td>idiotic</td>\n",
              "      <td>6.968227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50099</th>\n",
              "      <td>stupidity</td>\n",
              "      <td>7.565816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25993</th>\n",
              "      <td>idiots</td>\n",
              "      <td>8.628643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25982</th>\n",
              "      <td>idiot</td>\n",
              "      <td>8.634393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50086</th>\n",
              "      <td>stupid</td>\n",
              "      <td>9.609074</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a14573e9-dd23-4d25-a89c-e78b73a81631')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a14573e9-dd23-4d25-a89c-e78b73a81631 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a14573e9-dd23-4d25-a89c-e78b73a81631');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This seems to make sense. The words are clearly toxic."
      ],
      "metadata": {
        "id": "trjsCXIO24nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep dive\n",
        "\n",
        "Let us compare the following 4 sentences:\n",
        "- \"I have a muslim friend\"\n",
        "- \"I have a christian friend\"\n",
        "- \"I have a white friend\"\n",
        "- \"I have a black friend\"\n",
        "\n",
        "We will\n",
        "- call `classify_comment` to print the prediction made by the model\n",
        "- print the coefficients of the words in the sentence that are in the vocabulary\n",
        "\n",
        "This will be grouped in the function `classify_and_describe`.\n",
        "\n",
        "Feel free to try out more comments, to see how the model classifies them.\n"
      ],
      "metadata": {
        "id": "fpQaAvi23GZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_and_describe(comment):\n",
        "  classify_comment(comment)\n",
        "  print(coefficients[coefficients.word.isin(comment.split())])"
      ],
      "metadata": {
        "id": "1QR30Tek32LG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment_1 = \"I have a muslim friend\"\n",
        "comment_2 = \"I have a christian friend\"\n",
        "comment_3 = \"I have a white friend\"\n",
        "comment_4 = \"I have a black friend\""
      ],
      "metadata": {
        "id": "PxE99Urt4CHC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classify_and_describe(comment_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcAr_DwX4Qpt",
        "outputId": "061733b1-c7e6-458c-e923-617086ae10d3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOXIC I have a muslim friend\n",
            "         word     coeff\n",
            "21395  friend  0.047330\n",
            "24195    have -0.072698\n",
            "34872  muslim  1.866862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classify_and_describe(comment_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrIbN0VX4fze",
        "outputId": "6167f615-d1eb-4535-d034-973350c9acbe"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT TOXIC I have a christian friend\n",
            "            word     coeff\n",
            "10332  christian  0.213929\n",
            "21395     friend  0.047330\n",
            "24195       have -0.072698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classify_and_describe(comment_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1navUOqy4hqv",
        "outputId": "45c76f73-82f6-4130-f621-99cca527557b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT TOXIC I have a white friend\n",
            "         word     coeff\n",
            "21395  friend  0.047330\n",
            "24195    have -0.072698\n",
            "56818   white  1.271812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classify_and_describe(comment_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_FMxNtN4lrv",
        "outputId": "c4d9f0b2-0373-40d9-e068-63384bca8cd5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOXIC I have a black friend\n",
            "         word     coeff\n",
            "6917    black  2.067671\n",
            "21395  friend  0.047330\n",
            "24195    have -0.072698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "None of the 4 examples should have been marked as toxic. The model however classifies 2 of them as toxic. This is a sign of bias: the model seems to be in favor of *christian* and against *muslim*, and in favor of *white* and against *black*.\n",
        "\n"
      ],
      "metadata": {
        "id": "NJamb9T55AtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happened here is called **identity term bias**.\n",
        "\n",
        "Our model is biased towards indentity terms: terms characterizing a specific group of people such as \"Muslim\" and \"black\". This type of bias is commonly reflected in false positives: non-toxic comments with identity terms are incorrectly classified as toxic. This is due to the frequency with which some identity terms appear in toxic and attacking comments. \n",
        "\n",
        "As you have seen, language models are essentialy a probability distribution over words or sequences of words. They learn to correlate certain genders, races, ethnicities and religions with toxic words, because these toxic words over overrepresented in the texts. "
      ],
      "metadata": {
        "id": "riwz-ExflGPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other possible types of biases\n",
        "\n",
        "Many types of bias can arise. We will now look at some examples and hypothetical cases. This list is by far complete and primarily serves as an eye-opener.\n",
        "\n",
        "#### Evaluation bias\n",
        "\n",
        "Suppose you have trained the model with comments primarily from users based in Canada, i.e. you have used training and test data from Canadian users. Your model performs really well on the test data. Next, the model is used in Australia and it does not perform well at all, because of differences in English. \n",
        "\n",
        "Another typical example of evaluation bias is training a model to predict voting turnout across the country, but you have trained and evaluated it on local data.\n",
        "\n",
        "#### Sample bias\n",
        "\n",
        "This type of bias happens when the training data does not accurately represent the real world. For instance when the training data mostly contains comments from right wing supporters.\n",
        "\n",
        "Another example: suppose you want to build a speech-to-text system. To do this you need a lot of audio, together with the transcriptions. A practical way to do this would be to use audiobooks. However, most audiobooks are narrated by educated, middle aged, white men. Systems trained on such data underperform on users of different ethnic or socio-economic background.\n",
        "\n",
        "#### Annotation bias\n",
        "\n",
        "The data we have used is annotated: each sentence had a label. The way these labels have been chosen can also lead to bias. In a study from the Allen Institute for AI, Carnegie Mellon and the University of Washington, researchers investigated how differences in dialect can lead to racial biases in automatic hate speech detection, see [The risk of Racial Bias in Hate Speech Detection](https://maartensap.com/pdfs/sap2019risk.pdf). They found that the people responsible for annotating the data are more likely to label phrases in the African American English (AAE) dialect more toxic than American English variants, despite the fact that these are considered not toxic by the AAE speakers.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hIxfnMTjBSjc"
      }
    }
  ]
}